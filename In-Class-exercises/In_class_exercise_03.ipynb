{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "In-class-exercise-03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilveldanda/A-Visual-History-of-Nobel-Prize-Winners/blob/master/In-Class-exercises/In_class_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ehgGKptGKkW"
      },
      "source": [
        "## The third In-class-exercise (9/29/2021, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSfPMuZvGKkY"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLYV8Xz2GKkZ"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "wgtJx0c5GKkZ",
        "outputId": "d47bb2be-86dc-4efe-fbae-5b3881f680d8"
      },
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "I have taken imdb reviews of users and trying to classify their reviews. I have used 5 different features to build ML models.\n",
        "The dataset is transformed into flat features which can be used in a machine learning model. \n",
        "This step also includes the process of creating new features from the existing data.\n",
        "\n",
        "Feature Engineering:\n",
        "\n",
        "      1) Count Vectors as features\n",
        "      2) TF-IDF Vectors as features\n",
        "        Word level\n",
        "        N-Gram level\n",
        "        Character level\n",
        "      3) Word Embeddings as features\n",
        "      4) Text / NLP based features\n",
        "      5) Topic Models as features\n",
        "\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nI have taken imdb reviews of users and trying to classify their reviews. I have used 5 different features to build ML models.\\nThe dataset is transformed into flat features which can be used in a machine learning model. \\nThis step also includes the process of creating new features from the existing data.\\n\\nFeature Engineering:\\n\\n      1) Count Vectors as features\\n      2) TF-IDF Vectors as features\\n        Word level\\n        N-Gram level\\n        Character level\\n      3) Word Embeddings as features\\n      4) Text / NLP based features\\n      5) Topic Models as features\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MokeslClGKka"
      },
      "source": [
        "Question 2 (20 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsZ2iF26BXqf",
        "outputId": "7b94e5ac-f479-4766-cf5c-d47f2cb8899f"
      },
      "source": [
        "\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,209 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,800 kB]\n",
            "Fetched 5,261 kB in 3s (1,699 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (93.0.4577.63-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 80 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: use options instead of chrome_options\n",
            "  del sys.path[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAPycwkUBceC"
      },
      "source": [
        "\n",
        "import pandas as pd \n",
        "# Import Selenium and its sub libraries\n",
        "import selenium \n",
        "from selenium import webdriver\n",
        "# Import BS4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzLaChQrBjch"
      },
      "source": [
        "\n",
        "def get_reviews(url) -> DataFrame:\n",
        "  driver.get(url)\n",
        "  driver.implicitly_wait(1) \n",
        "  # Set up action to click on 'load more' button\n",
        "  page = 1\n",
        "  #We want at least 1000 review, so get 50 at a safe number\n",
        "  while page<10:  \n",
        "      try:\n",
        "          load_more = driver.find_element_by_id('load-more-trigger')\n",
        "          load_more.click()\n",
        "          page+=1 \n",
        "      except:\n",
        "          break\n",
        "  # After fully expand the page, we will grab data from whole website\n",
        "  review = driver.find_elements_by_class_name('review-container')\n",
        "\n",
        "  #title = []\n",
        "  content = []\n",
        "  #rating = []\n",
        "  #date = []\n",
        "  user_name = []\n",
        "  for n in range(len(review)):\n",
        "      try:\n",
        "          #Some reviewers only give review text or rating without the other, \n",
        "          #so we use try/except here to make sure each block of content must has all the element before append them to the list\n",
        "          #Check if each review has all the elements\n",
        "          #ftitle = review[n].find_element_by_class_name('title').text\n",
        "          fcontent = review[n].find_element_by_class_name('content').get_attribute(\"textContent\").strip()\n",
        "          #frating = review[n].find_element_by_class_name('rating-other-user-rating').text\n",
        "          #fdate = review[n].find_element_by_class_name('review-date').text\n",
        "          fname = review[n].find_element_by_class_name('display-name-link').text\n",
        "          #Then add them to the respective list\n",
        "          #title.append(ftitle)\n",
        "          content.append(fcontent)\n",
        "          #rating.append(frating)\n",
        "          #date.append(fdate)\n",
        "          user_name.append(fname)\n",
        "      except:\n",
        "          continue\n",
        "  #Build data dictionary for dataframe\n",
        "  data = {'User name': user_name, \n",
        "          'Review text' : content\n",
        "      }\n",
        "  #Build dataframe for each movie to export\n",
        "  review = pd.DataFrame(data = data)\n",
        "  return review"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "15UwPoRmB47L",
        "outputId": "10d04d5c-c56e-4407-f841-f3fec8005aa8"
      },
      "source": [
        "df = get_reviews(\"https://www.imdb.com/title/tt6751668/reviews?ref_=tt_urv\")\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User name</th>\n",
              "      <th>Review text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mysticfall</td>\n",
              "      <td>It's not really a review but my attempt to exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jeremy_Urquhart</td>\n",
              "      <td>I am remarkably stingy with my 10/10 ratings. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jtindahouse</td>\n",
              "      <td>I can't remember the last time I saw a movie t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nehpetstephen</td>\n",
              "      <td>In a meritocracy, success and fortune are rese...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>keezo9uno</td>\n",
              "      <td>This movie is a gosh darn masterpiece. It will...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>ola-riser</td>\n",
              "      <td>After this movie, I'm now ready to search Crai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>RhapsodyReviews</td>\n",
              "      <td>Review:\\n'Parasite' is a black comedy-thriller...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>etzelryan76</td>\n",
              "      <td>Fascinating cinema that highlights how emotion...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>Karynsiegmann</td>\n",
              "      <td>This is my second viewing of Parasite and it's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>skakistikaprovlimata</td>\n",
              "      <td>We should keep it in a time capsule for the fu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>224 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                User name                                        Review text\n",
              "0              mysticfall  It's not really a review but my attempt to exp...\n",
              "1         Jeremy_Urquhart  I am remarkably stingy with my 10/10 ratings. ...\n",
              "2             jtindahouse  I can't remember the last time I saw a movie t...\n",
              "3           nehpetstephen  In a meritocracy, success and fortune are rese...\n",
              "4               keezo9uno  This movie is a gosh darn masterpiece. It will...\n",
              "..                    ...                                                ...\n",
              "219             ola-riser  After this movie, I'm now ready to search Crai...\n",
              "220       RhapsodyReviews  Review:\\n'Parasite' is a black comedy-thriller...\n",
              "221           etzelryan76  Fascinating cinema that highlights how emotion...\n",
              "222         Karynsiegmann  This is my second viewing of Parasite and it's...\n",
              "223  skakistikaprovlimata  We should keep it in a time capsule for the fu...\n",
              "\n",
              "[224 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1josR_zdKEqY"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['Review text'], df['User name'])\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgLGO38VG21J"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(df['Review text'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORGwDBypCZi7",
        "outputId": "108bba79-54f9-4e11-c923-671eca0de1bf"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern='\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['Review text'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['Review text'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['Review text'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y-YyWEiK3b8"
      },
      "source": [
        "df['char_count'] = df['Review text'].apply(len)\n",
        "df['word_count'] = df['Review text'].apply(lambda x: len(x.split()))\n",
        "df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
        "df['punctuation_count'] = df['Review text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
        "df['title_word_count'] = df['Review text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
        "df['upper_case_word_count'] = df['Review text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
        "\n",
        "pos_family = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "# function to check and get the part of speech tag count of a words in a given sentence\n",
        "def check_pos_tag(x, flag):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = textblob.TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_family[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "\n",
        "df['noun_count'] = df['Review text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
        "df['verb_count'] = df['Review text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
        "df['adj_count'] = df['Review text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
        "df['adv_count'] = df['Review text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
        "df['pron_count'] = df['Review text'].apply(lambda x: check_pos_tag(x, 'pron'))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "pHRWkHUpK3fg",
        "outputId": "fd0e8783-6e85-4bcf-9dca-e842172c346d"
      },
      "source": [
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User name</th>\n",
              "      <th>Review text</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>pron_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mysticfall</td>\n",
              "      <td>It's not really a review but my attempt to exp...</td>\n",
              "      <td>4538</td>\n",
              "      <td>778</td>\n",
              "      <td>5.825417</td>\n",
              "      <td>135</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>192</td>\n",
              "      <td>133</td>\n",
              "      <td>72</td>\n",
              "      <td>64</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Jeremy_Urquhart</td>\n",
              "      <td>I am remarkably stingy with my 10/10 ratings. ...</td>\n",
              "      <td>2020</td>\n",
              "      <td>364</td>\n",
              "      <td>5.534247</td>\n",
              "      <td>66</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>58</td>\n",
              "      <td>79</td>\n",
              "      <td>35</td>\n",
              "      <td>38</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jtindahouse</td>\n",
              "      <td>I can't remember the last time I saw a movie t...</td>\n",
              "      <td>1019</td>\n",
              "      <td>185</td>\n",
              "      <td>5.478495</td>\n",
              "      <td>26</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>46</td>\n",
              "      <td>31</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nehpetstephen</td>\n",
              "      <td>In a meritocracy, success and fortune are rese...</td>\n",
              "      <td>4643</td>\n",
              "      <td>791</td>\n",
              "      <td>5.862374</td>\n",
              "      <td>150</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>182</td>\n",
              "      <td>138</td>\n",
              "      <td>60</td>\n",
              "      <td>78</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>keezo9uno</td>\n",
              "      <td>This movie is a gosh darn masterpiece. It will...</td>\n",
              "      <td>510</td>\n",
              "      <td>67</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>ola-riser</td>\n",
              "      <td>After this movie, I'm now ready to search Crai...</td>\n",
              "      <td>389</td>\n",
              "      <td>42</td>\n",
              "      <td>9.046512</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>RhapsodyReviews</td>\n",
              "      <td>Review:\\n'Parasite' is a black comedy-thriller...</td>\n",
              "      <td>1484</td>\n",
              "      <td>259</td>\n",
              "      <td>5.707692</td>\n",
              "      <td>36</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>59</td>\n",
              "      <td>50</td>\n",
              "      <td>29</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>etzelryan76</td>\n",
              "      <td>Fascinating cinema that highlights how emotion...</td>\n",
              "      <td>448</td>\n",
              "      <td>47</td>\n",
              "      <td>9.333333</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>Karynsiegmann</td>\n",
              "      <td>This is my second viewing of Parasite and it's...</td>\n",
              "      <td>937</td>\n",
              "      <td>143</td>\n",
              "      <td>6.506944</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>skakistikaprovlimata</td>\n",
              "      <td>We should keep it in a time capsule for the fu...</td>\n",
              "      <td>337</td>\n",
              "      <td>33</td>\n",
              "      <td>9.911765</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>224 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                User name  ... pron_count\n",
              "0              mysticfall  ...         55\n",
              "1         Jeremy_Urquhart  ...         32\n",
              "2             jtindahouse  ...         19\n",
              "3           nehpetstephen  ...         75\n",
              "4               keezo9uno  ...          8\n",
              "..                    ...  ...        ...\n",
              "219             ola-riser  ...          6\n",
              "220       RhapsodyReviews  ...         20\n",
              "221           etzelryan76  ...          2\n",
              "222         Karynsiegmann  ...         13\n",
              "223  skakistikaprovlimata  ...          2\n",
              "\n",
              "[224 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0s3a0MVK3jA"
      },
      "source": [
        "# train a LDA Model\n",
        "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
        "X_topics = lda_model.fit_transform(xtrain_count)\n",
        "topic_word = lda_model.components_ \n",
        "vocab = count_vect.get_feature_names()\n",
        "\n",
        "# view the topic models\n",
        "n_top_words = 10\n",
        "topic_summaries = []\n",
        "for i, topic_dist in enumerate(topic_word):\n",
        "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
        "    topic_summaries.append(' '.join(topic_words))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whh7ylOhLjJ_",
        "outputId": "ccdd529f-8ac2-43dd-c02d-fd3a6b6780ca"
      },
      "source": [
        "topic_summaries"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the of a to and i is this in it',\n",
              " 'the is and of this a to movie are in',\n",
              " 'the years s cell topical prize to exceptionally chan descriptive',\n",
              " 'gorily trying car manipulates overnight changes preys thingh dramatic nit',\n",
              " 'this of was helpful the i to and it t',\n",
              " 'the and i to this a of movie that s',\n",
              " 'the and of this to a i was it that',\n",
              " 'the of a in i and is it to that',\n",
              " 'artist glorifying crafty hadn helped dollars gripping meaty youtube redeem',\n",
              " 'jarring taek life afflicted 91 grounded symbolic rewatch humor numbing',\n",
              " 'the and i a it was of that in this',\n",
              " 'i didnt was engaging know thanked my out refused it',\n",
              " 'the it this of and a in i to helpful',\n",
              " 'the this of and to a in i helpful that',\n",
              " 'i one winners caution mission or risk hand 40 blurb',\n",
              " 'the and a to i of this it is in',\n",
              " 'believability strongest students tackle violence fact if hardworking equality foundation',\n",
              " 'the to a and of it is but about i',\n",
              " 'the of and a to this it in i is',\n",
              " 'it i this the of out is was helpful one']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq8jGYKcGKkb"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLR_3gjBH0Ii"
      },
      "source": [
        "# Model Building\n",
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsLS6IvWVtXH"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fu0d5NMVAEG",
        "outputId": "6b8fe9ac-d024-4bb6-e67c-98f8ab05fb6a"
      },
      "source": [
        "# Naive Bayes on Count Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print(\"NB, Count Vectors: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Word Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print( \"NB, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print( \"NB, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Character Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"NB, CharLevel Vectors: \", accuracy)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NB, Count Vectors:  0.0\n",
            "NB, WordLevel TF-IDF:  0.0\n",
            "NB, N-Gram Vectors:  0.0\n",
            "NB, CharLevel Vectors:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fcfDd24V2O0"
      },
      "source": [
        "### Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wOk1EHWVObU",
        "outputId": "e9c5cf21-4037-46df-e360-1ef5b7fe126a"
      },
      "source": [
        "# Linear Classifier on Count Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
        "print (\"LR, Count Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print (\"LR, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print (\"LR, CharLevel Vectors: \", accuracy)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR, Count Vectors:  0.0\n",
            "LR, WordLevel TF-IDF:  0.017857142857142856\n",
            "LR, N-Gram Vectors:  0.0\n",
            "LR, CharLevel Vectors:  0.017857142857142856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuAhoWsUVgi2",
        "outputId": "0e34691c-7cd7-4894-be39-37dc99a7f8ef"
      },
      "source": [
        "# SVM on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print (\"SVM, N-Gram Vectors: \", accuracy)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM, N-Gram Vectors:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o7UwhkfeV-s2",
        "outputId": "3a79fb6a-95ac-4641-eb47-ce0860770fb4"
      },
      "source": [
        "# Important features ranking\n",
        "\"\"\"\n",
        "TF-IDF Vectors as features\n",
        "Word Embeddings as features\n",
        "Topic Models as features\n",
        "Text / NLP based features\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTF-IDF Vectors as features\\nWord Embeddings as features\\nTopic Models as features\\nText / NLP based features\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJHW3SKpcqQU"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}